# Showcase Project for Apache Flink

MONITORING / prometheus

## Terraform

```bash
# Initializes the Terraform working directory
terraform init

export TF_VAR_confluent_cloud_api_key="XXX"
export TF_VAR_confluent_cloud_api_secret="YYY"
export TF_VAR_confluent_cloud_environment_id="env-05rzn6"
export TF_VAR_confluent_cloud_kafka_cluster_id="lkc-77owpp"

# Generates the execution plan, showing what actions Terraform would take  
terraform plan  

# Creates or updates infrastructure according to the Terraform configuration  
terraform apply --auto-approve  

# Forces Terraform to destroy and recreate the specified resource
terraform apply -replace=confluent_connector.fleet_mgmt_description  

# Reads an output from a Terraform state file and prints the value
terraform output -json | jq '.resource_ids.value'
```

## Flink - Explore

```bash
# Authenticate with Confluent Cloud and save credentials for future use
confluent login --save

# Start an interactive Flink SQL shell session within the specified compute pool and environment
confluent flink shell --compute-pool lfcp-kz6p52 --environment env-05rzn6

# If you are using the Flink SQL console client, you need to select the appropriate catalog and database
USE CATALOG `demo-c9791e24`;   # Set the active catalog
USE `demo-cluster`;            # Set the active database

# List available catalogs, databases, and tables
SHOW CATALOGS;    # Display all available catalogs
SHOW DATABASES;   # List databases within the selected catalog
SHOW TABLES;      # Show tables in the active database

# Get metadata about a specific table
DESCRIBE `demo_fleet_mgmt_description`;          # Show column definitions and types
DESCRIBE EXTENDED `demo_fleet_mgmt_description`; # Show additional table metadata

# Retrieve the SQL statement used to create the table
SHOW CREATE TABLE `demo_fleet_mgmt_description`;
```

## Select Queries

The Flink tables are filled with synthetic data generated by Datagen connectors.

[System Columns: $rowtime](https://docs.confluent.io/cloud/current/flink/reference/statements/create-table.html#system-columns)

```sql
-- Retrieve all records from the table
SELECT *, `$rowtime` AS `ts` FROM `demo_fleet_mgmt_description`;

SELECT *, `$rowtime` AS `ts` FROM `demo_fleet_mgmt_description` /*+ OPTIONS('scan.startup.mode'='latest-offset') */;

-- Retrieve a subset of rows based on specified conditions
SELECT *
  FROM `demo_fleet_mgmt_description`
  WHERE driver_name LIKE 'Z%';

-- Retrieve specific fields from the table limiting the results to 10 rows
SELECT vehicle_id, driver_name, $rowtime
  FROM `demo_fleet_mgmt_description`
  WHERE driver_name LIKE 'Z%';
  LIMIT 10;
```

[Dynamic Table Options / Hints](https://docs.confluent.io/cloud/current/flink/reference/statements/hints.html)

## Group Aggregation Queries

[Group Aggregation Queries in Confluent Cloud for Apache Flink](https://docs.confluent.io/cloud/current/flink/reference/queries/group-aggregation.html)

```sql
-- Get the total number of vehicles records in the table (including duplicates)
SELECT COUNT(`vehicle_id`) AS `total`
  FROM `demo_fleet_mgmt_description`;

-- Get the number of unique customers by counting distinct customer IDs
SELECT COUNT(DISTINCT `vehicle_id`) AS `unique`
  FROM `demo_fleet_mgmt_description`;
```

## Window Aggregation Queries

[Window Aggregation Queries in Confluent Cloud for Apache Flink](https://docs.confluent.io/cloud/current/flink/reference/queries/window-aggregation.html)

```sql
-- The query performs a tumbling window aggregation on the sensors activity table,
-- counting the number of distinct activity records within fixed 5-minute intervals.
SELECT window_start, window_end, COUNT(DISTINCT vehicle_id) AS num_measures
FROM TABLE(TUMBLE(TABLE `demo_fleet_mgmt_sensors`, DESCRIPTOR(`$rowtime`), INTERVAL '5' MINUTES))
GROUP BY window_start, window_end;
```

## Flink Tables

### Append Mode

> 'changelog.mode' = 'append'

```sql
CREATE TABLE `demo_fleet_mgmt_location_detailed` (
`vehicle_id` INT NOT NULL,
`location` ROW < `latitude` DOUBLE NOT NULL, `longitude` DOUBLE NOT NULL > NOT NULL,
`driver_name` STRING NOT NULL,
`license_plate` STRING NOT NULL
) DISTRIBUTED BY HASH(`vehicle_id`) INTO 5 BUCKETS;

-- Use the following command to verify the structure of the created table  
SHOW CREATE TABLE `demo_fleet_mgmt_location_detailed`;  
```

### Upsert Mode

> 'changelog.mode' = 'upsert'

```sql
CREATE TABLE `demo_fleet_mgmt_location_latest` (
`vehicle_id` INT PRIMARY KEY NOT ENFORCED,
`location` ROW < `latitude` DOUBLE NOT NULL, `longitude` DOUBLE NOT NULL > NOT NULL,
`driver_name` STRING NOT NULL,
`license_plate` STRING NOT NULL
) DISTRIBUTED BY HASH(`vehicle_id`) INTO 3 BUCKETS;

-- Use the following command to verify the structure of the created table  
SHOW CREATE TABLE `demo_fleet_mgmt_location_latest`;
```

## Join Queries

[Join Queries in Confluent Cloud for Apache Flink](https://docs.confluent.io/cloud/current/flink/reference/queries/joins.html)

```sql
INSERT INTO `demo_fleet_mgmt_location_detailed`
SELECT l.vehicle_id, l.location.latitude, l.location.longitude, d.driver_name, d.license_plate
  FROM `demo_fleet_mgmt_location` l
  INNER JOIN `demo_fleet_mgmt_description` d ON l.vehicle_id = d.vehicle_id;

-- Use the following command to verify the number of records inserted 
SELECT COUNT(*) AS `number` FROM demo_fleet_mgmt_location_detailed;
```

```sql
INSERT INTO `demo_fleet_mgmt_location_latest`
SELECT l.vehicle_id, l.location.latitude, l.location.longitude, d.driver_name, d.license_plate
  FROM `demo_fleet_mgmt_location` l
  INNER JOIN `demo_fleet_mgmt_description` d ON l.vehicle_id = d.vehicle_id;

-- Use the following command to verify the number of records inserted 
SELECT COUNT(*) AS `number` FROM demo_fleet_mgmt_location_detailed;
```

## Metadata Columns

[Metadata Columns](https://docs.confluent.io/cloud/current/flink/reference/statements/create-table.html#metadata-columns)

```sql
ALTER TABLE demo_fleet_mgmt_location_latest ADD `partition` BIGINT METADATA VIRTUAL;
ALTER TABLE demo_fleet_mgmt_location_latest ADD `offset` BIGINT METADATA VIRTUAL;

SELECT vehicle_id, driver_name, license_plate, `partition`, `offset` 
  FROM demo_fleet_mgmt_location_latest /*+ OPTIONS('scan.startup.mode'='latest-offset') */;
```

## Watermarks

> A watermark in Flink is used to track the progress of event time and provide a way to trigger time-based operations.

[Watermark Clause](https://docs.confluent.io/cloud/current/flink/reference/statements/create-table.html#watermark-clause)

```sql
-- Provides a sequential numbering of rows based on the event time ($rowtime).
SELECT ROW_NUMBER() OVER (ORDER BY $rowtime ASC) AS `number`, *
  FROM `demo_fleet_mgmt_location_detailed`;

-- Adjust the watermark to be 10 seconds earlier than the event time  
ALTER TABLE `demo_fleet_mgmt_location_detailed`
  MODIFY WATERMARK FOR $rowtime AS $rowtime - INTERVAL '10' SECOND;

-- Verify that the table now uses the custom watermark instead of SOURCE_WATERMARK()  
DESCRIBE EXTENDED `demo_fleet_mgmt_location_detailed`;  

-- Drop the watermark
ALTER TABLE `demo_fleet_mgmt_location_detailed`
  DROP WATERMARK;
```

## Flink Views

[CREATE VIEW Statement in Confluent Cloud](https://docs.confluent.io/cloud/current/flink/reference/statements/create-view.html#)

> **In what scenarios should I prefer using a Flink View instead of a Table?**  
>  
> - Views are virtual, whereas tables are materialized.  
> - Views are only accessible within CC Flink and cannot be consumed by external Kafka clients.  
>  
> Use a view when you want to encapsulate common query logic, allowing you 
> and others to reuse it across multiple queries without duplicating code.